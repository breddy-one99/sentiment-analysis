{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4d3a497d-8c0c-48eb-9ea4-9c4d9152dec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "721a8cf6-b981-4524-8e3d-b4d43e890dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9031a0b9-d8d4-4e10-88e2-97151299a3fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8feab57b-d382-470e-8f65-9d573c641cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"IMDB Dataset.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a92b507b-3073-4c20-8467-0e0dab23c793",
   "metadata": {},
   "source": [
    "### Part 1: Removing numbers/digits from the review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e5e5cdbf-1a40-45bb-aa57-945458ea9629",
   "metadata": {},
   "outputs": [],
   "source": [
    "def review_digit(text):\n",
    "    return re.sub('\\d+', '', text)\n",
    "for index, row in df.iterrows():\n",
    "    df.at[index,\"review\"] = review_digit(row[\"review\"]);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c488969-f0e5-4e6d-b5d2-34ab00d8206f",
   "metadata": {},
   "source": [
    "### Part 2: Converting all the text to lowercase (it seems this is a requirement for ML algos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "231c6dc6-8326-4df9-9654-27f149ed7571",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in df.iterrows():\n",
    "    df.at[index,\"review\"] = row[\"review\"].lower();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "893f8245-55fb-4f58-81c6-db47b3cccbe3",
   "metadata": {},
   "source": [
    "### Part 3: Removing the HTML tags from the review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e127858b-4bb1-4c26-a055-61cec25b3eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_html_tags(text):\n",
    "    clean = re.compile('<.*?>')\n",
    "    return re.sub(clean, ' ', text);\n",
    "for index, row in df.iterrows():\n",
    "    df.at[index,\"review\"] = remove_html_tags(row[\"review\"]);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9082c39e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Part 4: Removing any contractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "23120d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "import contractions\n",
    "for index, row in df.iterrows():\n",
    "    df.at[index,\"review\"] = contractions.fix(row[\"review\"]);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ba05c38-be18-4285-bfb4-723261cf3d4d",
   "metadata": {},
   "source": [
    "### Part 4: Removing punctuation from the review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "58a7f942-852f-4cce-ad47-35a227c63d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_pun(text):\n",
    "    return re.sub(r'[^\\w\\s]', ' ', text)\n",
    "for index, row in df.iterrows():\n",
    "    df.at[index,\"review\"] = remove_pun(row[\"review\"]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2d2db1dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Part 5: Removing any extra spaces created by above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b4bc7f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_spaces(text):\n",
    "    return re.sub(r'\\s+', ' ', text)\n",
    "for index, row in df.iterrows():\n",
    "    df.at[index,\"review\"] = remove_spaces(row[\"review\"]);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2ac69d7-ff26-4918-995f-d040ac6d64bd",
   "metadata": {},
   "source": [
    "### Part 6: Removing stopwords from the review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "dcb0fa03-6ea8-4c24-a03a-b08d4756aa07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e621acc9-fa8a-435a-8e87-532bc8817202",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\meyer\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\meyer\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "stop_words = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0634a415-7d7c-42b9-8946-0985963bd186",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in df.iterrows():\n",
    "    df.at[index,\"review\"] = ' '.join(word for word in row[\"review\"].split() if word not in stop_words);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df6cd49c-4aa9-48a1-9c44-1a7152353922",
   "metadata": {},
   "source": [
    "### Part 7: Applying lemmitization on the review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b69bf033-f7c2-491c-ab24-320543aa8e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "03923be3-ac40-4b78-b6c4-100ce19fe3da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\meyer\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "abea68a4-323e-4281-8ebf-68f5e51e74e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\meyer\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\meyer\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('omw-1.4')\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d4632ca-846f-4241-a572-bede73b9b7d8",
   "metadata": {},
   "source": [
    "##### Note: in order to run the code below it was giving some error saying nltk.download('punkt') and nltk.download('omw-1.4') is required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "69288be8-2308-434d-9af9-e2f79bd0dc45",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet\n",
    "def get_wordnet_pos(treebank_tag):\n",
    "\n",
    "    if treebank_tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif treebank_tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif treebank_tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif treebank_tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        # As default pos in lemmatization is Noun\n",
    "        return wordnet.NOUN\n",
    "for index, row in df.iterrows():\n",
    "    review_word_tag_list = nltk.pos_tag(nltk.word_tokenize(row[\"review\"]))\n",
    "    df.at[index,\"review\"] =' '.join([lemmatizer.lemmatize(word,get_wordnet_pos(pos)) for (word, pos) in review_word_tag_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f5d692e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Part 8: Encode the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e5d494df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "Encoder = LabelEncoder()\n",
    "df.sentiment = Encoder.fit_transform(df.sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "dedbd450-7fc3-4000-ae25-6947ae3f770b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"cleanseDAta.csv\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "919abee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Run svm against the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "59fd1b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "### grab the first 70% of data to use as training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "237142a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "percentToTrain = 70\n",
    "trainingData = df.head(int(len(df)*(percentToTrain/100)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "0819f94d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        one reviewer mention watch oz episode hook rig...\n",
       "1        wonderful little production film technique una...\n",
       "2        think wonderful way spend time hot summer week...\n",
       "3        basically family little boy jake think zombie ...\n",
       "4        petter mattei love time money visually stunnin...\n",
       "                               ...                        \n",
       "49995    think movie right good job creative original f...\n",
       "49996    bad plot bad dialogue bad act idiotic direct a...\n",
       "49997    catholic teach parochial elementary school nun...\n",
       "49998    go disagree previous comment side maltin one s...\n",
       "49999    one expect star trek movie high art fan expect...\n",
       "Name: review, Length: 50000, dtype: object"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "percentToTest = 100 - percentToTrain\n",
    "testData = df.tail(int(len(df) * (percentToTest/100)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "d797cb6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Vectorize the data ( here we can do a lot of different ways we will do a default way for now)\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "Tfidf_vect = TfidfVectorizer(max_features=5000)\n",
    "Tfidf_vect.fit(df.review)\n",
    "Train_X_Tfidf  = Tfidf_vect.transform(trainingData.review)\n",
    "Test_X_Tfidf = Tfidf_vect.transform(testData.review)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "536f0810",
   "metadata": {},
   "outputs": [],
   "source": [
    "### run svm against the data\n",
    "from sklearn import svm\n",
    "SVM = svm.SVC(C=1.0, kernel='linear', degree=3, gamma='auto')\n",
    "SVM.fit(Train_X_Tfidf,trainingData.sentiment);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "3b475fbb",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'accuracy_score' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [64], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m predictions_SVM \u001b[38;5;241m=\u001b[39m SVM\u001b[38;5;241m.\u001b[39mpredict(Test_X_Tfidf)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Use accuracy_score function to get the accuracy\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSVM Accuracy Score -> \u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[43maccuracy_score\u001b[49m(predictions_SVM, testData\u001b[38;5;241m.\u001b[39msentiment)\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m100\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'accuracy_score' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "predictions_SVM = SVM.predict(Test_X_Tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "00bcfbca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Accuracy Score ->  88.36666666666667\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "print(\"SVM Accuracy Score -> \",accuracy_score(predictions_SVM, testData.sentiment)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79e6a850",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
