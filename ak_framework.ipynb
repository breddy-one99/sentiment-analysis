{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d3486522",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "936f0da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('IMDB Dataset.csv', encoding = 'Latin-1')\n",
    "df['sentiment'] = df['sentiment'].map({'positive': 1, 'negative': 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8ab588e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>I thought this movie did a down right good job...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>Bad plot, bad dialogue, bad acting, idiotic di...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>I am a Catholic taught in parochial elementary...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>I'm going to have to disagree with the previou...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>No one expects the Star Trek movies to be high...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review  sentiment\n",
       "0      One of the other reviewers has mentioned that ...          1\n",
       "1      A wonderful little production. <br /><br />The...          1\n",
       "2      I thought this was a wonderful way to spend ti...          1\n",
       "3      Basically there's a family where a little boy ...          0\n",
       "4      Petter Mattei's \"Love in the Time of Money\" is...          1\n",
       "...                                                  ...        ...\n",
       "49995  I thought this movie did a down right good job...          1\n",
       "49996  Bad plot, bad dialogue, bad acting, idiotic di...          0\n",
       "49997  I am a Catholic taught in parochial elementary...          0\n",
       "49998  I'm going to have to disagree with the previou...          0\n",
       "49999  No one expects the Star Trek movies to be high...          0\n",
       "\n",
       "[50000 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc54cb5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove HTML formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "acb3c941",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "for i in range(len(df)):\n",
    "    df['review'][i] = BeautifulSoup(df['review'][i]).get_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fce26b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d6acd49a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "for i in range(len(df)):\n",
    "    df[\"review\"][i] = re.sub(\"[,.;:'-*]\", \" \", df[\"review\"][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "764ba47f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Covert to lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ad0464bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(df)):\n",
    "    df[\"review\"][i] = df[\"review\"][i].lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17d34716",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c0aa6429",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "for w in stopwords.words('english'):\n",
    "    df['review'] = df[\"review\"].str.replace(' ' + str(w) + ' ', ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ad6e33c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stemming the words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "920af994",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import LancasterStemmer\n",
    "\n",
    "lancaster = LancasterStemmer()\n",
    "\n",
    "for i in range(len(df)):\n",
    "    df['review'][i] = df['review'][i].split(' ')\n",
    "    df['review'][i] = [lancaster.stem(y) for y in df['review'][i]]\n",
    "    df['review'][i] = ' '.join(df['review'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "57a13f33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'on review ment watch 1 oz episod hook  right  exact hap first thing struck oz brut unflinch scen viol  set right word go  trust  show faint heart timid  show pul punch regard drug  sex viol  hardc  class us word cal oz nicknam giv oswald maxim sec stat penit  focus main emerald city  expery sect prison cel glass front fac inward  priv high agend  em city hom many  ary  muslim  gangsta  latino  christians  it  ir    scuffl  dea star  dodgy deal shady agr nev far away would say main ap show due fact goe show dar  forget pretty pict paint mainstream audy  forget charm  forget rom   oz mess around  first episod ev saw struck nasty sur  say ready  watch  develop tast oz  got accustom high level graph viol  viol  injust  crook guard sold nickel  inm kil ord get away  wel man  middl class inm turn prison bitch due lack street skil prison expery  watch oz  may becom comfort uncomfort view    that get touch dark sid '"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df['review'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e256ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vectorization of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d12b1880",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer(max_features = 5000) \n",
    "\n",
    "x = vectorizer.fit_transform(df['review']).toarray()\n",
    "y = df['sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "23500c88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "73b3cd57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        1\n",
       "1        1\n",
       "2        1\n",
       "3        0\n",
       "4        1\n",
       "        ..\n",
       "49995    1\n",
       "49996    0\n",
       "49997    0\n",
       "49998    0\n",
       "49999    0\n",
       "Name: sentiment, Length: 50000, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "643d9aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "46cd6c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size = 0.25, random_state=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "072d2421",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sc = StandardScaler()\n",
    "\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d3c38539",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.05371202, -0.08443223, -0.33188426, ..., -0.07828176,\n",
       "        -0.05862699, -0.04765582],\n",
       "       [-0.05371202, -0.08443223, -0.33188426, ..., -0.07828176,\n",
       "        -0.05862699, -0.04765582],\n",
       "       [-0.05371202, -0.08443223,  1.61884613, ..., -0.07828176,\n",
       "        -0.05862699, -0.04765582],\n",
       "       ...,\n",
       "       [-0.05371202, -0.08443223, -0.33188426, ..., -0.07828176,\n",
       "        -0.05862699, -0.04765582],\n",
       "       [-0.05371202, -0.08443223, -0.33188426, ..., -0.07828176,\n",
       "        -0.05862699, -0.04765582],\n",
       "       [-0.05371202, -0.08443223,  5.52030691, ..., -0.07828176,\n",
       "        -0.05862699, -0.04765582]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "702c4d20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.05371202, -0.08443223, -0.33188426, ..., -0.07828176,\n",
       "        -0.05862699, -0.04765582],\n",
       "       [-0.05371202, -0.08443223, -0.33188426, ..., -0.07828176,\n",
       "        -0.05862699, -0.04765582],\n",
       "       [-0.05371202, -0.08443223, -0.33188426, ..., -0.07828176,\n",
       "        -0.05862699, -0.04765582],\n",
       "       ...,\n",
       "       [-0.05371202, -0.08443223, -0.33188426, ..., -0.07828176,\n",
       "        -0.05862699, -0.04765582],\n",
       "       [-0.05371202, -0.08443223, -0.33188426, ..., -0.07828176,\n",
       "        -0.05862699, -0.04765582],\n",
       "       [-0.05371202, -0.08443223, -0.33188426, ..., -0.07828176,\n",
       "        -0.05862699, -0.04765582]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8efe5108",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38274    0\n",
       "49945    0\n",
       "36190    1\n",
       "44920    0\n",
       "14665    0\n",
       "        ..\n",
       "24828    1\n",
       "20414    1\n",
       "9526     0\n",
       "42539    0\n",
       "10967    0\n",
       "Name: sentiment, Length: 37500, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "55970e5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35083    1\n",
       "9005     0\n",
       "23836    0\n",
       "42777    1\n",
       "13222    1\n",
       "        ..\n",
       "28652    0\n",
       "8070     0\n",
       "35178    1\n",
       "17922    0\n",
       "23951    0\n",
       "Name: sentiment, Length: 12500, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfd8a042",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2bee79eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logClassifier = LogisticRegression(random_state=11) \n",
    "logreg = LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
    "         intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
    "         penalty='elasticnet', random_state=None, solver='saga', tol=0.0001,l1_ratio=1,\n",
    "         verbose=0, warm_start=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fbbaf124",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(l1_ratio=1, multi_class='ovr', n_jobs=1,\n",
       "                   penalty='elasticnet', solver='saga')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8e4d6252",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********************\n",
      "Recall Score:     0.887\n",
      "Accuracy Score:   0.875\n",
      "Precision Score:  0.869\n",
      "F1 Score:         0.878\n",
      "***********************\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score,fbeta_score, recall_score, f1_score\n",
    "\n",
    "lb_predict = logreg.predict(X_test)\n",
    "print(\"***********************\")\n",
    "print(f\"{'Recall Score:':18}{recall_score(y_test, lb_predict):.3f}\")\n",
    "print(f\"{'Accuracy Score: ':18}{accuracy_score(y_test, lb_predict):.3f}\")\n",
    "print(f\"{'Precision Score: ':18}{precision_score(y_test, lb_predict):.3f}\")\n",
    "print(f\"{'F1 Score: ':18}{f1_score(y_test, lb_predict ):.3f}\")\n",
    "print(\"***********************\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97827128",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b0248e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "#Creating the model\n",
    "nb_model = GaussianNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e2c9f248",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB()"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ace0d98a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********************\n",
      "Recall Score:     0.552\n",
      "Accuracy Score:   0.701\n",
      "Precision Score:  0.794\n",
      "F1 Score:         0.651\n",
      "***********************\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score,fbeta_score, recall_score, f1_score\n",
    "\n",
    "nb_predict = nb_model.predict(X_test)\n",
    "print(\"***********************\")\n",
    "print(f\"{'Recall Score:':18}{recall_score(y_test, nb_predict):.3f}\")\n",
    "print(f\"{'Accuracy Score: ':18}{accuracy_score(y_test, nb_predict):.3f}\")\n",
    "print(f\"{'Precision Score: ':18}{precision_score(y_test, nb_predict):.3f}\")\n",
    "print(f\"{'F1 Score: ':18}{f1_score(y_test, nb_predict):.3f}\")\n",
    "print(\"***********************\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e658c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6305ad63",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "SVM = SVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "706dca0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "SVM.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7368a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score,fbeta_score, recall_score, f1_score\n",
    "\n",
    "svm_predict = SVM.predict(X_test)\n",
    "print(\"***********************\")\n",
    "print(f\"{'Recall Score:':18}{recall_score(y_test, svm_predict):.3f}\")\n",
    "print(f\"{'Accuracy Score: ':18}{accuracy_score(y_test, svm_predict):.3f}\")\n",
    "print(f\"{'Precision Score: ':18}{precision_score(y_test, svm_predict):.3f}\")\n",
    "print(f\"{'F1 Score: ':18}{f1_score(y_test, svm_predict):.3f}\")\n",
    "print(\"***********************\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d5cc7f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17719d6e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb190fb9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
